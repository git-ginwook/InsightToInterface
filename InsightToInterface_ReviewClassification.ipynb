{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/git-ginwook/InsightToInterface/blob/OutOfMemoryError/InsightToInterface_ReviewClassification.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DGp-FxOA6c5Q"
      },
      "source": [
        "# Movie Classification"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "14WdVg4E66sf"
      },
      "source": [
        "## Dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NEvsKUZn3AAY"
      },
      "source": [
        "\n",
        "[IMDB Dataset of 50K Movie Reviews](https://www.kaggle.com/datasets/lakshmi25npathi/imdb-dataset-of-50k-movie-reviews/code)\n",
        "\n",
        "- connect dataset directly from Kaggle"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zKF_6g3f5H45"
      },
      "outputs": [],
      "source": [
        "import kagglehub\n",
        "\n",
        "# Download latest version\n",
        "path = kagglehub.dataset_download(\"lakshmi25npathi/imdb-dataset-of-50k-movie-reviews\")\n",
        "\n",
        "print(\"Path to dataset files:\", path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "vN4Y1U735WGO"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "\n",
        "reviews_df = pd.read_csv(path + \"/IMDB Dataset.csv\")\n",
        "reviews_df.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "idAjF2Ep98yQ"
      },
      "source": [
        "## GPU Device Setup"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kd9uwWaH-tzh"
      },
      "source": [
        "### 1. Verify A100 GPU set up"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "a6chhxqX-DUe"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "\n",
        "# Check if GPU is available\n",
        "if torch.cuda.is_available():\n",
        "    device = torch.device(\"cuda\")  # Automatically selects the first available GPU\n",
        "    gpu_name = torch.cuda.get_device_name(0)\n",
        "\n",
        "    # Check if it's an A100 GPU\n",
        "    if \"A100\" in gpu_name:\n",
        "        print(f\"Successfully set up {gpu_name}!\")\n",
        "    else:\n",
        "        print(f\"GPU assigned: {gpu_name}. Note: It's not an A100 GPU.\")\n",
        "else:\n",
        "    device = torch.device(\"cpu\")\n",
        "    print(\"GPU not available. Using CPU.\")\n",
        "\n",
        "# Print CUDA version\n",
        "print(f\"CUDA Version: {torch.version.cuda}\")\n",
        "print(f\"PyTorch Version: {torch.__version__}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jWLuXQv9-8Pd"
      },
      "source": [
        "### 2. Verify GPU performance"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IVRpDrpt--OS"
      },
      "outputs": [],
      "source": [
        "import time\n",
        "\n",
        "# Dummy tensor operation to benchmark GPU\n",
        "device = torch.device(\"cuda\")\n",
        "size = 10000\n",
        "\n",
        "# Create random tensors\n",
        "a = torch.randn(size, size, device=device)\n",
        "b = torch.randn(size, size, device=device)\n",
        "\n",
        "# Time matrix multiplication on GPU\n",
        "start = time.time()\n",
        "c = torch.matmul(a, b)\n",
        "torch.cuda.synchronize()  # Wait for GPU to finish\n",
        "end = time.time()\n",
        "\n",
        "print(f\"Time for matrix multiplication on GPU: {end - start:.4f} seconds\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FYTr7QrE62wM"
      },
      "source": [
        "## Models"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OPIjiegz3QT1"
      },
      "source": [
        "\n",
        "[Customer Segmentation using LLMs: Advanced Clustering Techniques for Effective Targeting](https://ai.plainenglish.io/customer-segmentation-using-llms-advanced-clustering-techniques-for-effective-targeting-493116116ab6)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DEclc5Iz6lqK"
      },
      "source": [
        "### 1. BERT for Text Embedding -> review sentiments (e.g., + or -)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Rx86dfuXRUXH"
      },
      "source": [
        "Batch processing\n",
        "- make sure to clean GPU memory by running `torch.cuda.empty_cache()`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "smpSJe2MRQdH"
      },
      "outputs": [],
      "source": [
        "from transformers import BertTokenizer, BertModel\n",
        "import torch\n",
        "import pandas as pd\n",
        "from sklearn.cluster import KMeans\n",
        "\n",
        "# Load the pre-trained BERT tokenizer and model\n",
        "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
        "model = BertModel.from_pretrained('bert-base-uncased').to(device)  # use GPU\n",
        "\n",
        "# Sample customer reviews\n",
        "customer_reviews = reviews_df[\"review\"].to_list()\n",
        "\n",
        "# Parameters\n",
        "batch_size = 1000  # Number of reviews per batch\n",
        "num_clusters = 2  # Number of clusters for K-Means\n",
        "\n",
        "# Initialize DataFrame to store results\n",
        "results = pd.DataFrame(columns=['Review', 'Cluster'])\n",
        "\n",
        "# Process in batches\n",
        "for i in range(0, len(customer_reviews), batch_size):\n",
        "    # Get the current batch\n",
        "    batch_reviews = customer_reviews[i:i + batch_size]\n",
        "\n",
        "    # Tokenize and encode the batch\n",
        "    inputs = tokenizer(batch_reviews, return_tensors='pt', padding=True, truncation=True, max_length=512)\n",
        "    inputs = {key: value.to(device) for key, value in inputs.items()}  # Load data to GPU\n",
        "\n",
        "    # Get the embeddings from the BERT model\n",
        "    with torch.no_grad():\n",
        "        outputs = model(**inputs)\n",
        "        embeddings = outputs.last_hidden_state.mean(dim=1)\n",
        "\n",
        "        del outputs # delete unnecessary variables to reclaim memory\n",
        "\n",
        "    # Free GPU memory after extracting embeddings\n",
        "    torch.cuda.empty_cache()\n",
        "\n",
        "    # Convert embeddings to numpy array for clustering\n",
        "    embeddings = embeddings.cpu().numpy()  # Bring back output from GPU to CPU\n",
        "\n",
        "    # Perform K-Means clustering on the batch\n",
        "    kmeans = KMeans(n_clusters=num_clusters, random_state=42)\n",
        "    labels = kmeans.fit_predict(embeddings)\n",
        "\n",
        "    # Add the batch results to the results DataFrame\n",
        "    batch_results = pd.DataFrame({\n",
        "        'Review': batch_reviews,\n",
        "        'Cluster': labels\n",
        "    })\n",
        "    results = pd.concat([results, batch_results], ignore_index=True)\n",
        "\n",
        "# Show the clusters\n",
        "print(results)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Calculate Accuracy Score"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# Map 'positive' to 1 and 'negative' to 0 in the reviews_df\n",
        "reviews_df['sentiment'] = reviews_df['sentiment'].map({'positive': 1, 'negative': 0})\n",
        "\n",
        "# Calculate the accuracy score\n",
        "accuracy = accuracy_score(reviews_df['sentiment'], results['Cluster'])\n",
        "\n",
        "# Print the accuracy score\n",
        "print(\"Accuracy:\", accuracy)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T4a5MOfCcbP1"
      },
      "source": [
        "Visualization"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AL5QGizlY8QT"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Count the number of reviews in each cluster\n",
        "cluster_counts = results['Cluster'].value_counts()\n",
        "\n",
        "# Map cluster numbers to meaningful labels\n",
        "cluster_labels = {0: 'Negative', 1: 'Positive'}\n",
        "cluster_counts.index = cluster_counts.index.map(cluster_labels)\n",
        "\n",
        "# Define colors for each cluster\n",
        "colors = ['red', 'green']  # Specify colors for clusters 0 and 1\n",
        "\n",
        "# Plot the counts as a bar graph\n",
        "plt.figure(figsize=(8, 6))\n",
        "cluster_counts.plot(kind='barh', color=colors)\n",
        "\n",
        "# Adjust the axis limits to include the annotations\n",
        "max_count = cluster_counts.max()\n",
        "plt.xlim(0, max_count * 1.1)  # Add 10% extra space to the right of the largest bar\n",
        "\n",
        "# Add title and xy-labels\n",
        "plt.title('Sentiment of Movie Reviews')\n",
        "plt.xlabel('Number of Reviews')\n",
        "plt.ylabel('Sentiment')\n",
        "\n",
        "# Annotate bars with the total count\n",
        "for index, value in enumerate(cluster_counts):\n",
        "    plt.text(value + 100, index, f'{value:,}', va='center')  # Add commas to the number\n",
        "\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zl1Muma4ceTb"
      },
      "source": [
        "Evaluation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G8Z4q_ii5T5G"
      },
      "source": [
        "### 2. Latent Dirichlet Allocation (LDA) -> review themes (e.g., price, quality)\n",
        "- Not working yet. need to investigate"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kXQ3y7nk7cOW"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YCAGxSLzVmWL"
      },
      "source": [
        "### 3. Sentiment Analysis\n",
        "- TBD"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "authorship_tag": "ABX9TyPWusrrarNrn1zLOf4RCkR3",
      "gpuType": "A100",
      "include_colab_link": true,
      "machine_shape": "hm",
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
