{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOeg54hCMywY9bMDQQaHNWJ",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/pksungwan/InsightToInterface/blob/imdb-bert-clustering/IMDB_Clustering_using_BERT.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Clustering Movies and TV Shows using BERT Embedding.\n",
        "\n",
        "[BERT model](https://huggingface.co/google-bert/bert-base-uncased) can be used to represent input text into vector embedding. Input text is movies and tv shows descriptions. One can use the output of the model (embedding) to do clustering.\n",
        "\n",
        "source - https://medium.com/ai-in-plain-english/customer-segmentation-using-llms-advanced-clustering-techniques-for-effective-targeting-493116116ab6\n"
      ],
      "metadata": {
        "id": "OLKf4Xe_I7CW"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-97lcf9H0rYD",
        "outputId": "58dae1ee-5a64-4407-a0e9-57131d6ce669"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                                              Review  Cluster\n",
            "0  Two imprisoned men bond over a number of years...        1\n",
            "1  An organized crime dynasty's aging patriarch t...        0\n",
            "2  When the menace known as the Joker wreaks havo...        1\n",
            "3  The early life and career of Vito Corleone in ...        1\n",
            "4  A jury holdout attempts to prevent a miscarria...        1\n",
            "5  Gandalf and Aragorn lead the World of Men agai...        1\n",
            "6  The lives of two mob hitmen, a boxer, a gangst...        1\n",
            "7  In German-occupied Poland during World War II,...        0\n",
            "8  A thief who steals corporate secrets through t...        1\n",
            "9  An insomniac office worker and a devil-may-car...        1\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import kagglehub\n",
        "import pandas as pd\n",
        "from sklearn.cluster import KMeans\n",
        "from transformers import BertTokenizer, BertModel\n",
        "\n",
        "# Write device agnostic code\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# Import IMDB dataset\n",
        "path = kagglehub.dataset_download(\"harshitshankhdhar/imdb-dataset-of-top-1000-movies-and-tv-shows\")\n",
        "imdb_data = pd.read_csv(path + \"/imdb_top_1000.csv\")\n",
        "\n",
        "# Load the pre-trained BERT tokenizer and model\n",
        "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
        "model = BertModel.from_pretrained('bert-base-uncased').to(device)\n",
        "\n",
        "# Movies and TV Shows Descriptions\n",
        "descriptions = imdb_data[\"Overview\"][:10].to_list()\n",
        "\n",
        "# Tokenize and encode the reviews\n",
        "inputs = tokenizer(descriptions, return_tensors='pt', padding=True, truncation=True)\n",
        "inputs.to(device)\n",
        "\n",
        "# Get the embeddings from the BERT model\n",
        "with torch.no_grad():\n",
        "    outputs = model(**inputs)\n",
        "    embeddings = outputs.last_hidden_state.mean(dim=1)\n",
        "\n",
        "# Convert embeddings to a numpy array for clustering\n",
        "embeddings = embeddings.cpu().numpy()\n",
        "\n",
        "# Perform K-Means clustering\n",
        "kmeans = KMeans(n_clusters=2)\n",
        "labels = kmeans.fit_predict(embeddings)\n",
        "\n",
        "# Add the results to a DataFrame for better visualization\n",
        "df = pd.DataFrame({\n",
        "    'Review': descriptions,\n",
        "    'Cluster': labels\n",
        "})\n",
        "\n",
        "# Show the clusters\n",
        "print(df)"
      ]
    }
  ]
}